{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:47.929165Z",
     "iopub.status.busy": "2020-08-13T15:44:47.928180Z",
     "iopub.status.idle": "2020-08-13T15:44:47.934267Z",
     "shell.execute_reply": "2020-08-13T15:44:47.933600Z"
    },
    "papermill": {
     "duration": 0.047094,
     "end_time": "2020-08-13T15:44:47.934422",
     "exception": false,
     "start_time": "2020-08-13T15:44:47.887328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:48.010690Z",
     "iopub.status.busy": "2020-08-13T15:44:48.009757Z",
     "iopub.status.idle": "2020-08-13T15:44:50.577898Z",
     "shell.execute_reply": "2020-08-13T15:44:50.577169Z"
    },
    "papermill": {
     "duration": 2.611124,
     "end_time": "2020-08-13T15:44:50.578054",
     "exception": false,
     "start_time": "2020-08-13T15:44:47.966930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:50.656284Z",
     "iopub.status.busy": "2020-08-13T15:44:50.655328Z",
     "iopub.status.idle": "2020-08-13T15:44:50.749984Z",
     "shell.execute_reply": "2020-08-13T15:44:50.749158Z"
    },
    "papermill": {
     "duration": 0.138921,
     "end_time": "2020-08-13T15:44:50.750178",
     "exception": false,
     "start_time": "2020-08-13T15:44:50.611257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:50.847938Z",
     "iopub.status.busy": "2020-08-13T15:44:50.824335Z",
     "iopub.status.idle": "2020-08-13T15:44:50.868329Z",
     "shell.execute_reply": "2020-08-13T15:44:50.868935Z"
    },
    "papermill": {
     "duration": 0.086936,
     "end_time": "2020-08-13T15:44:50.869121",
     "exception": false,
     "start_time": "2020-08-13T15:44:50.782185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see the first columns with “head” function. If you pass some number in it, it could show the first “n” number\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:50.949748Z",
     "iopub.status.busy": "2020-08-13T15:44:50.948645Z",
     "iopub.status.idle": "2020-08-13T15:44:50.955387Z",
     "shell.execute_reply": "2020-08-13T15:44:50.954603Z"
    },
    "papermill": {
     "duration": 0.053879,
     "end_time": "2020-08-13T15:44:50.955521",
     "exception": false,
     "start_time": "2020-08-13T15:44:50.901642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:51.028154Z",
     "iopub.status.busy": "2020-08-13T15:44:51.026932Z",
     "iopub.status.idle": "2020-08-13T15:44:51.030640Z",
     "shell.execute_reply": "2020-08-13T15:44:51.029868Z"
    },
    "papermill": {
     "duration": 0.042289,
     "end_time": "2020-08-13T15:44:51.030773",
     "exception": false,
     "start_time": "2020-08-13T15:44:50.988484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the total number of na values “the missing” values on train dataframe is 6965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:51.111534Z",
     "iopub.status.busy": "2020-08-13T15:44:51.109959Z",
     "iopub.status.idle": "2020-08-13T15:44:51.116395Z",
     "shell.execute_reply": "2020-08-13T15:44:51.115634Z"
    },
    "papermill": {
     "duration": 0.052654,
     "end_time": "2020-08-13T15:44:51.116532",
     "exception": false,
     "start_time": "2020-08-13T15:44:51.063878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:51.191528Z",
     "iopub.status.busy": "2020-08-13T15:44:51.190479Z",
     "iopub.status.idle": "2020-08-13T15:44:51.194109Z",
     "shell.execute_reply": "2020-08-13T15:44:51.193301Z"
    },
    "papermill": {
     "duration": 0.043087,
     "end_time": "2020-08-13T15:44:51.194243",
     "exception": false,
     "start_time": "2020-08-13T15:44:51.151156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the total number of na values “the missing” values on the test is 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:51.278816Z",
     "iopub.status.busy": "2020-08-13T15:44:51.277921Z",
     "iopub.status.idle": "2020-08-13T15:44:51.922698Z",
     "shell.execute_reply": "2020-08-13T15:44:51.921992Z"
    },
    "papermill": {
     "duration": 0.694663,
     "end_time": "2020-08-13T15:44:51.922830",
     "exception": false,
     "start_time": "2020-08-13T15:44:51.228167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you groupby any column and count you see the count of the some reccuring strings or number. \n",
    "# The count values gives how many times they reccure. If we divide them with total count, we can find the possibilities of them. \n",
    "# The method I used is a aggregate filling method to all na values in a for loop\n",
    "for name in train.columns:\n",
    "    x = train[name].isna().sum()\n",
    "    if x > 0:\n",
    "        val_list = np.random.choice(train.groupby(name).count().index, x, p=train.groupby(name).count()['Id'].values /sum(train.groupby(name).count()['Id'].values))\n",
    "        train.loc[train[name].isna(), name] = val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:52.006068Z",
     "iopub.status.busy": "2020-08-13T15:44:52.005017Z",
     "iopub.status.idle": "2020-08-13T15:44:53.053437Z",
     "shell.execute_reply": "2020-08-13T15:44:53.052593Z"
    },
    "papermill": {
     "duration": 1.096729,
     "end_time": "2020-08-13T15:44:53.053582",
     "exception": false,
     "start_time": "2020-08-13T15:44:51.956853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we loop on train.columns and if this column has na values that means if x > 0, we randomly choice from the list that is the groupby dataframe indexes. \n",
    "# and the probabilities are the count of them divided total sum. \n",
    "# Therefore, we collect a list with “x” element in it with most probable elements of the this serie. \n",
    "# This way, we can fill the na values according to probabistic approach and simulation technics.\n",
    "# Again same process is applied into test dataframe.\n",
    "for name in test.columns:\n",
    "    x = test[name].isna().sum()\n",
    "    if x > 0:\n",
    "        val_list = np.random.choice(test.groupby(name).count().index, x, p=test.groupby(name).count()['Id'].values /sum(test.groupby(name).count()['Id'].values))\n",
    "        test.loc[test[name].isna(), name] = val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.137514Z",
     "iopub.status.busy": "2020-08-13T15:44:53.136711Z",
     "iopub.status.idle": "2020-08-13T15:44:53.152784Z",
     "shell.execute_reply": "2020-08-13T15:44:53.152035Z"
    },
    "papermill": {
     "duration": 0.064452,
     "end_time": "2020-08-13T15:44:53.152926",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.088474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the end, the na values sum is zero both for train and test dataframe\n",
    "sum(train.isna().sum())\n",
    "sum(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.228624Z",
     "iopub.status.busy": "2020-08-13T15:44:53.227496Z",
     "iopub.status.idle": "2020-08-13T15:44:53.230641Z",
     "shell.execute_reply": "2020-08-13T15:44:53.231387Z"
    },
    "papermill": {
     "duration": 0.043185,
     "end_time": "2020-08-13T15:44:53.231562",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.188377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then other process that is encoding the string values comes. \n",
    "# With the help of labelencoder in sklearn, I create a total for loop for all columns and easily we can label them all fastest way we can. \n",
    "# First for train columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.314508Z",
     "iopub.status.busy": "2020-08-13T15:44:53.313297Z",
     "iopub.status.idle": "2020-08-13T15:44:53.552539Z",
     "shell.execute_reply": "2020-08-13T15:44:53.551765Z"
    },
    "papermill": {
     "duration": 0.286224,
     "end_time": "2020-08-13T15:44:53.552670",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.266446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "Alley\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "# First I need to concat the test and train data\n",
    "train_df = train.drop('SalePrice',axis = 1)\n",
    "data = pd.concat([train_df,test])\n",
    "le = preprocessing.LabelEncoder()\n",
    "for name in data.columns:\n",
    "    if data[name].dtypes == \"O\":\n",
    "        print(name)\n",
    "        data[name] = data[name].astype(str)\n",
    "        train[name] = train[name].astype(str)\n",
    "        test[name] = test[name].astype(str)\n",
    "        le.fit(data[name])\n",
    "        train[name] = le.transform(train[name])\n",
    "        test[name] = le.transform(test[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.636785Z",
     "iopub.status.busy": "2020-08-13T15:44:53.635643Z",
     "iopub.status.idle": "2020-08-13T15:44:53.638962Z",
     "shell.execute_reply": "2020-08-13T15:44:53.639595Z"
    },
    "papermill": {
     "duration": 0.050828,
     "end_time": "2020-08-13T15:44:53.639774",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.588946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second for test columns\n",
    "for name in test.columns:\n",
    "    if test[name].dtypes == \"O\":\n",
    "        test[name] = test[name].to_string()\n",
    "        le.fit(test[name])\n",
    "        test[name] = le.transform(test[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.720886Z",
     "iopub.status.busy": "2020-08-13T15:44:53.720057Z",
     "iopub.status.idle": "2020-08-13T15:44:53.730199Z",
     "shell.execute_reply": "2020-08-13T15:44:53.729378Z"
    },
    "papermill": {
     "duration": 0.054476,
     "end_time": "2020-08-13T15:44:53.730335",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.675859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First I tran my train data with random forest algorithm\n",
    "# This is a proven algorithm with its success. First I try to see results about it\n",
    "X = train.drop('SalePrice',axis = 1)\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:53.813460Z",
     "iopub.status.busy": "2020-08-13T15:44:53.812284Z",
     "iopub.status.idle": "2020-08-13T15:44:54.275372Z",
     "shell.execute_reply": "2020-08-13T15:44:54.274509Z"
    },
    "papermill": {
     "duration": 0.509146,
     "end_time": "2020-08-13T15:44:54.275510",
     "exception": false,
     "start_time": "2020-08-13T15:44:53.766364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then I train the “X” data with “y” label and take the predictions from “X_test” data which is test data features\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "predictions = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.353504Z",
     "iopub.status.busy": "2020-08-13T15:44:54.352324Z",
     "iopub.status.idle": "2020-08-13T15:44:54.355822Z",
     "shell.execute_reply": "2020-08-13T15:44:54.355245Z"
    },
    "papermill": {
     "duration": 0.0444,
     "end_time": "2020-08-13T15:44:54.355968",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.311568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The result is: 2140642920.0111065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.436318Z",
     "iopub.status.busy": "2020-08-13T15:44:54.435384Z",
     "iopub.status.idle": "2020-08-13T15:44:54.440600Z",
     "shell.execute_reply": "2020-08-13T15:44:54.439963Z"
    },
    "papermill": {
     "duration": 0.048347,
     "end_time": "2020-08-13T15:44:54.440736",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.392389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2140642920.0111065"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.528164Z",
     "iopub.status.busy": "2020-08-13T15:44:54.527066Z",
     "iopub.status.idle": "2020-08-13T15:44:54.532023Z",
     "shell.execute_reply": "2020-08-13T15:44:54.531166Z"
    },
    "papermill": {
     "duration": 0.053833,
     "end_time": "2020-08-13T15:44:54.532195",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.478362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# That seems very high. However, the log transformations change it to very low\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.616085Z",
     "iopub.status.busy": "2020-08-13T15:44:54.615068Z",
     "iopub.status.idle": "2020-08-13T15:44:54.618482Z",
     "shell.execute_reply": "2020-08-13T15:44:54.617680Z"
    },
    "papermill": {
     "duration": 0.047747,
     "end_time": "2020-08-13T15:44:54.618622",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.570875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This random search is used for random forest algorithm. You can use it for all the other machine learning algorithms if you want\n",
    "# Next, I extract PCA features with PCA analysis. The total column number is three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.706628Z",
     "iopub.status.busy": "2020-08-13T15:44:54.705508Z",
     "iopub.status.idle": "2020-08-13T15:44:54.874423Z",
     "shell.execute_reply": "2020-08-13T15:44:54.873777Z"
    },
    "papermill": {
     "duration": 0.217353,
     "end_time": "2020-08-13T15:44:54.874573",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.657220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644798635617486"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents_train = pca.fit_transform(X)\n",
    "principalComponents_test = pca.fit_transform(test)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:54.958518Z",
     "iopub.status.busy": "2020-08-13T15:44:54.957374Z",
     "iopub.status.idle": "2020-08-13T15:44:54.961176Z",
     "shell.execute_reply": "2020-08-13T15:44:54.960356Z"
    },
    "papermill": {
     "duration": 0.048193,
     "end_time": "2020-08-13T15:44:54.961328",
     "exception": false,
     "start_time": "2020-08-13T15:44:54.913135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then, I load these features into the “train” and “test” dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:55.064157Z",
     "iopub.status.busy": "2020-08-13T15:44:55.063295Z",
     "iopub.status.idle": "2020-08-13T15:44:55.066917Z",
     "shell.execute_reply": "2020-08-13T15:44:55.066283Z"
    },
    "papermill": {
     "duration": 0.063832,
     "end_time": "2020-08-13T15:44:55.067065",
     "exception": false,
     "start_time": "2020-08-13T15:44:55.003233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['component_1'] = [i[0] for i in principalComponents_train]\n",
    "train['component_2'] = [i[1] for i in principalComponents_train]\n",
    "train['component_3'] = [i[2] for i in principalComponents_train]\n",
    "test['component_1'] = [i[0] for i in principalComponents_test]\n",
    "test['component_2'] = [i[1] for i in principalComponents_test]\n",
    "test['component_3'] = [i[2] for i in principalComponents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:55.161492Z",
     "iopub.status.busy": "2020-08-13T15:44:55.154438Z",
     "iopub.status.idle": "2020-08-13T15:44:58.678823Z",
     "shell.execute_reply": "2020-08-13T15:44:58.679438Z"
    },
    "papermill": {
     "duration": 3.573037,
     "end_time": "2020-08-13T15:44:58.679632",
     "exception": false,
     "start_time": "2020-08-13T15:44:55.106595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0616438356164384"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again some steps for random forest algorithm\n",
    "X = train.drop('SalePrice',axis = 1)\n",
    "y = train['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "regr = RandomForestRegressor(n_estimators = 400,min_samples_split = 2,min_samples_leaf = 1,max_features= 'sqrt',max_depth =None,bootstrap= False)\n",
    "regr.fit(X, y)\n",
    "predictions = regr.predict(X)\n",
    "mean_squared_error(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:58.769580Z",
     "iopub.status.busy": "2020-08-13T15:44:58.768501Z",
     "iopub.status.idle": "2020-08-13T15:44:58.771159Z",
     "shell.execute_reply": "2020-08-13T15:44:58.771740Z"
    },
    "papermill": {
     "duration": 0.050355,
     "end_time": "2020-08-13T15:44:58.771910",
     "exception": false,
     "start_time": "2020-08-13T15:44:58.721555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The error rate is 2.166095890410959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:58.859527Z",
     "iopub.status.busy": "2020-08-13T15:44:58.858706Z",
     "iopub.status.idle": "2020-08-13T15:44:58.862084Z",
     "shell.execute_reply": "2020-08-13T15:44:58.861284Z"
    },
    "papermill": {
     "duration": 0.049011,
     "end_time": "2020-08-13T15:44:58.862221",
     "exception": false,
     "start_time": "2020-08-13T15:44:58.813210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This method is similar to ensemble learning. I use and bagging algorithm in the end. I had just used it. \n",
    "# for details you can search the function and library on the Google. \n",
    "# I was using 7 different regressor for machine learning table to use as ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:44:58.962442Z",
     "iopub.status.busy": "2020-08-13T15:44:58.961452Z",
     "iopub.status.idle": "2020-08-13T15:45:04.062770Z",
     "shell.execute_reply": "2020-08-13T15:45:04.063790Z"
    },
    "papermill": {
     "duration": 5.160631,
     "end_time": "2020-08-13T15:45:04.064107",
     "exception": false,
     "start_time": "2020-08-13T15:44:58.903476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_1 = RandomForestRegressor(n_estimators = 400,min_samples_split = 2,min_samples_leaf = 1,max_features= 'sqrt',max_depth =None,bootstrap= False)\n",
    "model_1.fit(X, y)\n",
    "predict_1 = model_1.predict(X)\n",
    "model_2= linear_model.Ridge()\n",
    "model_2.fit(X,y)\n",
    "predict_2 =model_2.predict(X)\n",
    "model_3 =KNeighborsRegressor(10,weights='uniform')\n",
    "model_3.fit(X,y)\n",
    "predict_3 = model_3.predict(X)\n",
    "model_4 = linear_model.BayesianRidge()\n",
    "model_4.fit(X,y)\n",
    "predict_4 =model_4.predict(X)\n",
    "model_5 = tree.DecisionTreeRegressor(max_depth=1)\n",
    "model_5.fit(X,y)\n",
    "predict_5 =model_5.predict(X)\n",
    "model_6= svm.SVR(C=1.0, epsilon=0.2)\n",
    "model_6.fit(X,y)\n",
    "predict_6 = model_6.predict(X)\n",
    "model_7 = xgb.XGBRegressor()\n",
    "model_7.fit(X,y)\n",
    "predict_7 = model_7.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:04.254474Z",
     "iopub.status.busy": "2020-08-13T15:45:04.253505Z",
     "iopub.status.idle": "2020-08-13T15:45:04.256017Z",
     "shell.execute_reply": "2020-08-13T15:45:04.256553Z"
    },
    "papermill": {
     "duration": 0.082309,
     "end_time": "2020-08-13T15:45:04.256725",
     "exception": false,
     "start_time": "2020-08-13T15:45:04.174416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then, I collect them in an other dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:04.351249Z",
     "iopub.status.busy": "2020-08-13T15:45:04.349975Z",
     "iopub.status.idle": "2020-08-13T15:45:04.352841Z",
     "shell.execute_reply": "2020-08-13T15:45:04.353456Z"
    },
    "papermill": {
     "duration": 0.0568,
     "end_time": "2020-08-13T15:45:04.353642",
     "exception": false,
     "start_time": "2020-08-13T15:45:04.296842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['SalePrice'] = y\n",
    "final_df['RandomForest'] = predict_1\n",
    "final_df['Ridge'] = predict_2\n",
    "final_df['Kneighboors'] = predict_3\n",
    "final_df['BayesianRidge'] = predict_4\n",
    "final_df['DecisionTreeRegressor'] = predict_5\n",
    "final_df['Svm'] = predict_6\n",
    "final_df['XGBoost'] = predict_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:04.444335Z",
     "iopub.status.busy": "2020-08-13T15:45:04.443334Z",
     "iopub.status.idle": "2020-08-13T15:45:04.447461Z",
     "shell.execute_reply": "2020-08-13T15:45:04.446781Z"
    },
    "papermill": {
     "duration": 0.053749,
     "end_time": "2020-08-13T15:45:04.447600",
     "exception": false,
     "start_time": "2020-08-13T15:45:04.393851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I loaded predictions into this dataframe. Next, I will use bagging algorithm for predictions\n",
    "# Again, if you print the errors on the data, the most accurate is random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:04.540319Z",
     "iopub.status.busy": "2020-08-13T15:45:04.538800Z",
     "iopub.status.idle": "2020-08-13T15:45:04.548075Z",
     "shell.execute_reply": "2020-08-13T15:45:04.547300Z"
    },
    "papermill": {
     "duration": 0.05925,
     "end_time": "2020-08-13T15:45:04.548203",
     "exception": false,
     "start_time": "2020-08-13T15:45:04.488953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7958047945205475\n",
      "946945734.8919315\n",
      "1741219362.1610205\n",
      "962036239.3139004\n",
      "3441133618.712952\n",
      "6624565269.417332\n",
      "2378896.673861799\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(final_df['SalePrice'], predict_1))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_2))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_3))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_4))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_5))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_6))\n",
    "print(mean_squared_error(final_df['SalePrice'], predict_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:04.639972Z",
     "iopub.status.busy": "2020-08-13T15:45:04.639188Z",
     "iopub.status.idle": "2020-08-13T15:45:26.075166Z",
     "shell.execute_reply": "2020-08-13T15:45:26.074519Z"
    },
    "papermill": {
     "duration": 21.486245,
     "end_time": "2020-08-13T15:45:26.075310",
     "exception": false,
     "start_time": "2020-08-13T15:45:04.589065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958904631580564\n"
     ]
    }
   ],
   "source": [
    "# After that, I take the functions and label from this final dataframe and train it with BaggingRegressor\n",
    "X_final = final_df.drop ('SalePrice', axis = 1) \n",
    "y_final = final_df ['SalePrice']\n",
    "model_last = RandomForestRegressor () \n",
    "model_last.fit (X_final, y_final)\n",
    "predict_final = model_last.predict (X_final)\n",
    "final_dt = RandomForestRegressor ()                    \n",
    "model_last = BaggingRegressor (base_estimator = final_dt, n_estimators = 40, random_state = 1, oob_score = True)\n",
    "model_last.fit (X_final, y_final) \n",
    "pred_final = model_last.predict (X_final)\n",
    "acc_oob = model_last.oob_score_ \n",
    "print (acc_oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:26.166401Z",
     "iopub.status.busy": "2020-08-13T15:45:26.165391Z",
     "iopub.status.idle": "2020-08-13T15:45:26.170430Z",
     "shell.execute_reply": "2020-08-13T15:45:26.169807Z"
    },
    "papermill": {
     "duration": 0.05391,
     "end_time": "2020-08-13T15:45:26.170569",
     "exception": false,
     "start_time": "2020-08-13T15:45:26.116659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761809.2242160281"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(predict_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:26.266253Z",
     "iopub.status.busy": "2020-08-13T15:45:26.264709Z",
     "iopub.status.idle": "2020-08-13T15:45:26.868803Z",
     "shell.execute_reply": "2020-08-13T15:45:26.867903Z"
    },
    "papermill": {
     "duration": 0.655598,
     "end_time": "2020-08-13T15:45:26.868977",
     "exception": false,
     "start_time": "2020-08-13T15:45:26.213379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Case\n",
    "# We predict previous model the test dataframe\n",
    "test_predictions_1 = model_1.predict(test)\n",
    "test_predictions_2 = model_2.predict(test)\n",
    "test_predictions_3 = model_3.predict(test)\n",
    "test_predictions_4 = model_4.predict(test)\n",
    "test_predictions_5 = model_5.predict(test)\n",
    "test_predictions_6 = model_6.predict(test)\n",
    "test_predictions_7 = model_7.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:26.981289Z",
     "iopub.status.busy": "2020-08-13T15:45:26.980350Z",
     "iopub.status.idle": "2020-08-13T15:45:26.987639Z",
     "shell.execute_reply": "2020-08-13T15:45:26.988436Z"
    },
    "papermill": {
     "duration": 0.068829,
     "end_time": "2020-08-13T15:45:26.988641",
     "exception": false,
     "start_time": "2020-08-13T15:45:26.919812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Next, I create another dataframe for test results\n",
    "test_final_df = pd.DataFrame()\n",
    "test_final_df['RandomForest'] = test_predictions_1\n",
    "test_final_df['Ridge'] = test_predictions_2\n",
    "test_final_df['Kneighboors'] = test_predictions_3\n",
    "test_final_df['BayesianRidge'] = test_predictions_4\n",
    "test_final_df['DecisionTreeRegressor'] = test_predictions_5\n",
    "test_final_df['Svm'] = test_predictions_6\n",
    "test_final_df['XGBoost'] = test_predictions_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:27.093669Z",
     "iopub.status.busy": "2020-08-13T15:45:27.092901Z",
     "iopub.status.idle": "2020-08-13T15:45:28.076825Z",
     "shell.execute_reply": "2020-08-13T15:45:28.076161Z"
    },
    "papermill": {
     "duration": 1.036523,
     "end_time": "2020-08-13T15:45:28.076973",
     "exception": false,
     "start_time": "2020-08-13T15:45:27.040450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, I predict the last dataframe with lastly trained model\n",
    "last_predictions = model_last.predict(test_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:28.171892Z",
     "iopub.status.busy": "2020-08-13T15:45:28.171034Z",
     "iopub.status.idle": "2020-08-13T15:45:28.179775Z",
     "shell.execute_reply": "2020-08-13T15:45:28.178901Z"
    },
    "papermill": {
     "duration": 0.059711,
     "end_time": "2020-08-13T15:45:28.179914",
     "exception": false,
     "start_time": "2020-08-13T15:45:28.120203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then, I load the submission csv\n",
    "submission = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:28.272459Z",
     "iopub.status.busy": "2020-08-13T15:45:28.271679Z",
     "iopub.status.idle": "2020-08-13T15:45:28.275410Z",
     "shell.execute_reply": "2020-08-13T15:45:28.275985Z"
    },
    "papermill": {
     "duration": 0.052931,
     "end_time": "2020-08-13T15:45:28.276181",
     "exception": false,
     "start_time": "2020-08-13T15:45:28.223250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then matching the right values with right indexis\n",
    "submission['SalePrice'] = last_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-13T15:45:28.368474Z",
     "iopub.status.busy": "2020-08-13T15:45:28.367642Z",
     "iopub.status.idle": "2020-08-13T15:45:28.436367Z",
     "shell.execute_reply": "2020-08-13T15:45:28.435384Z"
    },
    "papermill": {
     "duration": 0.117175,
     "end_time": "2020-08-13T15:45:28.436517",
     "exception": false,
     "start_time": "2020-08-13T15:45:28.319342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I changed this last_predictions with “test_predictions_1” variable. \n",
    "# Finally I write the csv file into kaggle platform. That is it. Then, you should find the output and submit it\n",
    "submission.to_csv ('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.042872,
     "end_time": "2020-08-13T15:45:28.523247",
     "exception": false,
     "start_time": "2020-08-13T15:45:28.480375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 45.859169,
   "end_time": "2020-08-13T15:45:28.675286",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-13T15:44:42.816117",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
